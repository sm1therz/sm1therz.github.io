<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>CUDA Toolkit Documentation 12.9 Update 1</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/omni-style.css" type="text/css" />
      <link rel="stylesheet" href="_static/api-styles.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/mermaid-init.js"></script>
        <script src="_static/design-tabs.js"></script>
        <script src="https://unpkg.com/mermaid@9.1.5/dist/mermaid.min.js"></script>
        <script>initMermaid();</script>
        <script src="https://docs.nvidia.com/cuda/_static/version.js"></script>
        <script src="https://docs.nvidia.com/cuda/_static/social-media.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="https://docs.nvidia.com/cuda/genindex.html" />
    <link rel="search" title="Search" href="https://docs.nvidia.com/cuda/search.html" />
    <link rel="next" title="Release Notes" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="#">
            <img src="https://docs.nvidia.com/cuda/_static/cuda_512.png" class="logo" alt="Logo"/>
          </a>


<div id="nvidia-search-input-widget"></div>
<script src="https://api-prod.nvidia.com/search/nvidia-search-input.js"></script>
<script>
  NvidiaSearchInput.mount({"apiUrl": "https://api-prod.nvidia.com/search/graphql", "destination": "search.html", "path": "/cuda/", "site": "https://docs.nvidia.com"});
</script>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html">Release Notes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html">Quick Start Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">Installation Guide Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda-installation-guide-microsoft-windows/index.html">Installation Guide Windows</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Programming Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/ada-compatibility-guide/index.html">Ada Compatibility Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/ada-tuning-guide/index.html">Ada Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/ampere-compatibility-guide/index.html">NVIDIA Ampere GPU Architecture Compatibility Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html">NVIDIA Ampere GPU Architecture Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/blackwell-compatibility-guide/index.html">Blackwell Compatibility Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/blackwell-tuning-guide/index.html">Blackwell Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html">Best Practices Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/hopper-compatibility-guide/index.html">Hopper Compatibility Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/hopper-tuning-guide/index.html">Hopper Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/inline-ptx-assembly/index.html">Inline PTX Assembly</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/maxwell-compatibility-guide/index.html">Maxwell Compatibility Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/maxwell-tuning-guide/index.html">Maxwell Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html">PTX ISA</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/pascal-compatibility-guide/index.html">Pascal Compatibility Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/pascal-tuning-guide/index.html">Pascal Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/ptx-writers-guide-to-interoperability/index.html">PTX Interoperability</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/turing-compatibility-guide/index.html">Turing Compatibility Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/turing-tuning-guide/index.html">Turing Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/video-technologies/video-codec-sdk/13.0/index.html">Video Decoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/volta-compatibility-guide/index.html">Volta Compatibility Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/volta-tuning-guide/index.html">Volta Tuning Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CUDA API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cudla-api/index.html">cuDLA API</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html">cuFFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html">cuFile API Reference Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/curand/index.html">cuRAND</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cusolver/index.html">cuSOLVER</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cusparse/index.html">cuSPARSE</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://nvlabs.github.io/cub/">CUB</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html">CUDA Driver API</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/index.html">CUDA Math API</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html">CUDA Runtime API</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://nvidia.github.io/libcudacxx/">CUDA C++ Standard Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/npp/index.html">NPP</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/nvblas/index.html">NVBLAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/nvfatbin/index.html">nvFatbin</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/nvjitlink/index.html">nvJitLink</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/nvjpeg/index.html">nvJPEG</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/nvrtc/index.html">NVRTC (Runtime Compilation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://nvidia.github.io/cccl/thrust/">Thrust</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PTX Compiler API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/ptx-compiler-api/index.html">PTX Compiler APIs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Miscellaneous</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cupti/index.html">CUPTI</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/deploy/cuda-compatibility/index.html">CUDA Compatibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/demo-suite/index.html">CUDA Demo Suite</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/debugger-api/index.html">Debugger API</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/eflow-users-guide/index.html">CUDA on EFLOW</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/gpudirect-rdma/index.html">GPUDirect RDMA</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/gpudirect-storage/index.html">GPUDirect Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html">Multi-Instance GPU (MIG)</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/vGPU/index.html">vGPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/wsl-user-guide/index.html">CUDA on WSL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tools</span></p>
<ul>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/compute-sanitizer/index.html">Compute Sanitizer</a></li>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html">CUDA Binary Utilities</a></li>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-gdb/index.html">CUDA-GDB</a></li>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">NVCC</a></li>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/nsight-compute/index.html">Nsight Compute</a></li>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/nsight-eclipse-plugins-guide/index.html">Nsight Eclipse Plugins Edition</a></li>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/nsightee-plugins-install-guide/index.html">Nsight Eclipse Plugins Installation Guide</a></li>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/nsight-systems/index.html">Nsight Systems</a></li>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/index.html">Nsight Visual Studio Edition</a></li>
    <li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html">Profiler</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">White Papers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/floating-point/index.html">Floating Point and IEEE 754</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/incomplete-lu-cholesky/index.html">Incomplete-LU and Cholesky Preconditioned Iterative Methods</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-for-tegra-appnote/index.html">CUDA for Tegra</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compiler SDK</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/libnvvm-api/index.html">libNVVM API</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/libdevice-users-guide/index.html">libdevice User’s Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/nvvm-ir-spec/index.html">NVVM IR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference and Legal</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-features-archive/index.html">CUDA Features Archive</a></li>
<li class="toctree-l1"><a class="reference internal" href="https://docs.nvidia.com/cuda/eula/index.html">EULA</a></li>
</ul>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">landing</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
      <li>CUDA Toolkit Documentation 12.9 Update 1</li>

      <li class="wy-breadcrumbs-aside">
	  <div id="breadcrumbs-container">
               <div id="release-info">
            
                  <a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Toolkit Archive</a>
                  -
                 
                  <a href="mailto:CUDAIssues@nvidia.com?subject=CUDA Toolkit Documentation Feedback">Send Feedback</a></div>
            </div>
      </li>
<li class="wy-breadcrumbs-aside">

  <span>&nbsp;</span>
</li>

  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="cuda-toolkit-documentation-v12-8">
<span id="cuda-toolkit"></span><h1>CUDA Toolkit Documentation 12.9 Update 1<a class="headerlink" href="#cuda-toolkit-documentation-v12-8" title="Permalink to this headline"></a></h1>
<p><strong>Develop, Optimize and Deploy GPU-Accelerated Apps</strong></p>
<p>The NVIDIA® CUDA® Toolkit provides a development environment for creating high performance GPU-accelerated
applications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated
embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers.
The toolkit includes GPU-accelerated libraries, debugging and optimization tools, a C/C++ compiler, and a runtime
library to deploy your application.</p>
<p>Using built-in capabilities for distributing computations across multi-GPU configurations, scientists and researchers
can develop applications that scale from single GPU workstations to cloud installations with thousands of GPUs.</p>
<hr class="docutils" />
<dl class="simple">
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html"><span class="doc">Release Notes</span></a></dt><dd><p>The Release Notes for the CUDA Toolkit.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-features-archive/index.html"><span class="doc">CUDA Features Archive</span></a></dt><dd><p>The list of CUDA features by release.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/eula/index.html"><span class="doc">EULA</span></a></dt>
<dd>
  <p>
    The CUDA Toolkit End User License Agreement applies to the NVIDIA CUDA Toolkit, 
    the NVIDIA CUDA Samples 
    (<a href="https://github.com/nvidia/cuda-samples" target="_blank" rel="noopener">view on GitHub</a>), 
    the NVIDIA Display Driver, NVIDIA Nsight tools (Visual Studio Edition), and the associated 
    documentation on CUDA APIs, programming model and development tools. If you do not agree with the 
    terms and conditions of the license agreement, then do not download or use the software.
  </p>
</dd>
</dl>
<hr class="docutils" />
<section id="installation-guides">
<h2>Installation Guides<a class="headerlink" href="#installation-guides" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html"><span class="doc">Quick Start Guide</span></a></dt><dd><p>This guide provides the minimal first-steps instructions for installation and verifying CUDA on a standard system.</p>
</dd>
<dt><a class="reference internal" href="cuda-installation-guide-microsoft-windows/index.html"><span class="doc">Installation Guide Windows</span></a></dt><dd><p>This guide discusses how to install and check for correct operation of the CUDA Development Tools on Microsoft Windows systems.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html"><span class="doc">Installation Guide Linux</span></a></dt><dd><p>This guide discusses how to install and check for correct operation of the CUDA Development Tools on GNU/Linux systems.</p>
</dd>
</dl>
</section>
<hr class="docutils" />
<section id="programming-guides">
<h2>Programming Guides<a class="headerlink" href="#programming-guides" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html"><span class="doc">Programming Guide</span></a></dt><dd><p>This guide provides a detailed discussion of the CUDA programming model and programming interface. It then describes the hardware implementation, and provides guidance on how to achieve maximum performance. The appendices include a list of all CUDA-enabled devices, detailed description of all extensions to the C++ language, listings of supported mathematical functions, C++ features supported in host and device code, details on texture fetching, technical specifications of various devices, and concludes by introducing the low-level driver API.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html"><span class="doc">Best Practices Guide</span></a></dt><dd><p>This guide presents established parallelization and optimization techniques and explains coding metaphors and idioms that can greatly simplify programming for CUDA-capable GPU architectures. The intent is to provide guidelines for obtaining the best performance from NVIDIA GPUs using the CUDA Toolkit.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/maxwell-compatibility-guide/index.html"><span class="doc">Maxwell Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Maxwell Architecture. This document provides guidance to ensure that your software applications are compatible with Maxwell.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/pascal-compatibility-guide/index.html"><span class="doc">Pascal Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Pascal Architecture. This document provides guidance to ensure that your software applications are compatible with Pascal.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/volta-compatibility-guide/index.html"><span class="doc">Volta Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Volta Architecture. This document provides guidance to ensure that your software applications are compatible with Volta.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/turing-compatibility-guide/index.html"><span class="doc">Turing Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Turing Architecture. This document provides guidance to ensure that your software applications are compatible with Turing.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/ampere-compatibility-guide/index.html"><span class="doc">NVIDIA Ampere GPU Architecture Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Ampere GPU Architecture. This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/hopper-compatibility-guide/index.html"><span class="doc">Hopper Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Hopper GPUs. This document provides guidance to ensure that your software applications are compatible with Hopper architecture.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/ada-compatibility-guide/index.html"><span class="doc">Ada Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Ada GPUs. This document provides guidance to ensure that your software applications are compatible with Ada architecture.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/blackwell-compatibility-guide/index.html"><span class="doc">Blackwell Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Blackwell GPUs. This document provides guidance to ensure that your software applications are compatible with Blackwell architecture.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/maxwell-tuning-guide/index.html"><span class="doc">Maxwell Tuning Guide</span></a></dt><dd><p>Maxwell is NVIDIA’s 4th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Kepler architecture should typically see speedups on the Maxwell architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Maxwell architectural features.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/pascal-tuning-guide/index.html"><span class="doc">Pascal Tuning Guide</span></a></dt><dd><p>Pascal is NVIDIA’s 5th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Maxwell architecture should typically see speedups on the Pascal architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Pascal architectural features.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/volta-tuning-guide/index.html"><span class="doc">Volta Tuning Guide</span></a></dt><dd><p>Volta is NVIDIA’s 6th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Pascal architecture should typically see speedups on the Volta architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Volta architectural features.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/turing-tuning-guide/index.html"><span class="doc">Turing Tuning Guide</span></a></dt><dd><p>Turing is NVIDIA’s 7th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Pascal architecture should typically see speedups on the Turing architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Turing architectural features.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html"><span class="doc">NVIDIA Ampere GPU Architecture Tuning Guide</span></a></dt><dd><p>NVIDIA Ampere GPU Architecture is NVIDIA’s 8th-generation architecture for CUDA compute applications. Applications that follow the best practices for the NVIDIA Volta architecture should typically see speedups on the NVIDIA Ampere GPU Architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging NVIDIA Ampere GPU Architecture’s features.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/hopper-tuning-guide/index.html"><span class="doc">Hopper Tuning Guide</span></a></dt><dd><p>Hopper GPU Architecture is NVIDIA’s 9th-generation architecture for CUDA compute applications. Applications that follow the best practices for the NVIDIA Volta architecture should typically see speedups on the Hopper GPU Architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Hopper GPU Architecture’s features.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/ada-tuning-guide/index.html"><span class="doc">Ada Tuning Guide</span></a></dt><dd><p>The NVIDIA® Ada GPU architecture is NVIDIA’s 10th-generation architecture for CUDA® compute applications. The NVIDIA Ada GPU architecture retains and extends the same CUDA programming model provided by previous NVIDIA GPU architectures such as NVIDIA Ampere and Turing architectures, and applications that follow the best practices for those architectures should typically see speedups on the NVIDIA Ada architecture without any code changes. This guide summarizes the ways that an application can be fine-tuned to gain additional speedups by leveraging the NVIDIA Ada GPU architecture’s features.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/blackwell-tuning-guide/index.html"><span class="doc">Blackwell Tuning Guide</span></a></dt><dd><p>The NVIDIA® Blackwell GPU architecture is NVIDIA’s latest architecture for CUDA® compute applications. The NVIDIA Blackwell GPU architecture retains and extends the same CUDA programming model provided by previous NVIDIA GPU architectures such as NVIDIA Ampere and Turing srchitectures, and applications that follow the best practices for those architectures should typically see speedups on the NVIDIA Blackwell architecture without any code changes. This guide summarizes the ways that an application can be fine-tuned to gain additional speedups by leveraging the NVIDIA Blackwell GPU architecture’s features.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html"><span class="doc">PTX ISA</span></a></dt><dd><p>This guide provides detailed instructions on the use of PTX, a low-level parallel thread execution virtual machine and instruction set architecture (ISA). PTX exposes the GPU as a data-parallel computing device.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/ptx-writers-guide-to-interoperability/index.html"><span class="doc">PTX Interoperability</span></a></dt><dd><p>This document shows how to write PTX that is ABI-compliant and interoperable with other CUDA code.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/inline-ptx-assembly/index.html"><span class="doc">Inline PTX Assembly</span></a></dt><dd><p>This document shows how to inline PTX (parallel thread execution) assembly language statements into CUDA code. It describes available assembler statement parameters and constraints, and the document also provides a list of some pitfalls that you may encounter.</p>
</dd>
</dl>
</section>
<hr class="docutils" />
<section id="cuda-api-references">
<h2>CUDA API References<a class="headerlink" href="#cuda-api-references" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html"><span class="doc">CUDA Runtime API</span></a></dt><dd><p>Fields in structures might appear in order that is different from the order of declaration.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html"><span class="doc">CUDA Driver API</span></a></dt><dd><p>Fields in structures might appear in order that is different from the order of declaration.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/index.html"><span class="doc">CUDA Math API</span></a></dt><dd><p>The CUDA math API.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html"><span class="doc">cuBLAS</span></a></dt><dd><p>The cuBLAS library is an implementation of BLAS (Basic Linear Algebra Subprograms) on top of the NVIDIA CUDA runtime. It allows the user to access the computational resources of NVIDIA Graphical Processing Unit (GPU), but does not auto-parallelize across multiple GPUs.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cudla-api/index.html"><span class="doc">cuDLA API</span></a></dt><dd><p>The cuDLA API.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/nvblas/index.html"><span class="doc">NVBLAS</span></a></dt><dd><p>The NVBLAS library is a multi-GPUs accelerated drop-in BLAS (Basic Linear Algebra Subprograms) built on top of the NVIDIA cuBLAS Library.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/nvjpeg/index.html"><span class="doc">nvJPEG</span></a></dt><dd><p>The nvJPEG Library provides high-performance GPU accelerated JPEG decoding functionality for image formats commonly used in deep learning and hyperscale multimedia applications.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html"><span class="doc">cuFFT</span></a></dt><dd><p>The cuFFT library user guide.</p>
</dd>
<dt><a class="reference internal" href="https://nvlabs.github.io/cub/"><span class="doc">CUB</span></a></dt><dd><p>The user guide for CUB.</p>
</dd>
<dt><a class="reference internal" href="https://nvidia.github.io/libcudacxx/"><span class="doc">CUDA C++ Standard Library</span></a></dt><dd><p>The API reference for libcu++, the CUDA C++ standard library.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html"><span class="doc">cuFile API Reference Guide</span></a></dt><dd><p>The NVIDIA® GPUDirect® Storage cuFile API Reference Guide provides information about the preliminary version of the cuFile API reference guide that is used in applications and frameworks to leverage GDS technology and describes the intent, context, and operation of those APIs, which are part of the GDS technology.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/curand/index.html"><span class="doc">cuRAND</span></a></dt><dd><p>The cuRAND library user guide.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cusparse/index.html"><span class="doc">cuSPARSE</span></a></dt><dd><p>The cuSPARSE library user guide.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/npp/index.html"><span class="doc">NPP</span></a></dt><dd><p>NVIDIA NPP is a library of functions for performing CUDA accelerated processing. The initial set of functionality in the library focuses on imaging and video processing and is widely applicable for developers in these areas. NPP will evolve over time to encompass more of the compute heavy tasks in a variety of problem domains. The NPP library is written to maximize flexibility, while maintaining high performance.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/nvjitlink/index.html"><span class="doc">nvJitLink</span></a></dt><dd><p>The user guide for the nvJitLink library.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/nvfatbin/index.html"><span class="doc">nvFatbin</span></a></dt><dd><p>The user guide for the nvFatbin library.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/nvrtc/index.html"><span class="doc">NVRTC (Runtime Compilation)</span></a></dt><dd><p>NVRTC is a runtime compilation library for CUDA C++. It accepts CUDA C++ source code in character string form and creates handles that can be used to obtain the PTX. The PTX string generated by NVRTC can be loaded by cuModuleLoadData and cuModuleLoadDataEx, and linked with other modules by cuLinkAddData of the CUDA Driver API. This facility can often provide optimizations and performance not possible in a purely offline static compilation.</p>
</dd>
<dt><a class="reference internal" href="https://nvidia.github.io/cccl/thrust/"><span class="doc">Thrust</span></a></dt><dd><p>The C++ parallel algorithms library.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cusolver/index.html"><span class="doc">cuSOLVER</span></a></dt><dd><p>The cuSOLVER library user guide.</p>
</dd>
</dl>
</section>
<hr class="docutils" />
<section id="ptx-compiler-api-references">
<h2>PTX Compiler API References<a class="headerlink" href="#ptx-compiler-api-references" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/ptx-compiler-api/index.html"><span class="doc">PTX Compiler APIs</span></a></dt><dd><p>This guide shows how to compile a PTX program into GPU assembly code using APIs provided by the static PTX Compiler library.</p>
</dd>
</dl>
</section>
<hr class="docutils" />
<section id="miscellaneous">
<dl class="simple">
<h2>Miscellaneous<a class="headerlink" href="#miscellaneous" title="Permalink to this headline"></a></h2>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/demo-suite/index.html"><span class="doc">CUDA Demo Suite</span></a></dt><dd><p>This document describes the demo applications shipped with the CUDA Demo Suite.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/wsl-user-guide/index.html"><span class="doc">CUDA on WSL</span></a></dt><dd><p>This guide is intended to help users get started with using NVIDIA CUDA on Windows Subsystem for Linux (WSL 2). The guide covers installation and running CUDA applications and containers in this environment.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html"><span class="doc">Multi-Instance GPU (MIG)</span></a></dt><dd><p>This edition of the user guide describes the Multi-Instance GPU feature of the NVIDIA® A100 GPU.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/deploy/cuda-compatibility/index.html"><span class="doc">CUDA Compatibility</span></a></dt><dd><p>This document describes CUDA Compatibility, including CUDA Enhanced Compatibility and CUDA Forward Compatible Upgrade.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cupti/index.html"><span class="doc">CUPTI</span></a></dt><dd><p>The CUPTI-API. The CUDA Profiling Tools Interface (CUPTI) enables the creation of profiling and tracing tools that target CUDA applications.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/debugger-api/index.html"><span class="doc">Debugger API</span></a></dt><dd><p>The CUDA debugger API.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/gpudirect-rdma/index.html"><span class="doc">GPUDirect RDMA</span></a></dt><dd><p>A technology introduced in Kepler-class GPUs and CUDA 5.0, enabling a direct path for communication between the GPU and a third-party peer device on the PCI Express bus when the devices share the same upstream root complex using standard features of PCI Express. This document introduces the technology and describes the steps necessary to enable a GPUDirect RDMA connection to NVIDIA GPUs within the Linux device driver model.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/gpudirect-storage/index.html"><span class="doc">GPUDirect Storage</span></a></dt><dd><p>The documentation for GPUDirect Storage.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/vGPU/index.html"><span class="doc">vGPU</span></a></dt><dd><p>vGPUs that support CUDA.</p>
</dd>
</dl>
</section>
<hr class="docutils" />
<section id="tools">
<h2>Tools<a class="headerlink" href="#tools" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html"><span class="doc">NVCC</span></a></dt><dd><p>This is a reference document for nvcc, the CUDA compiler driver. nvcc accepts a range of conventional compiler options, such as for defining macros and include/library paths, and for steering the compilation process.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-gdb/index.html"><span class="doc">CUDA-GDB</span></a></dt><dd><p>The NVIDIA tool for debugging CUDA applications running on Linux and QNX, providing developers with a mechanism for debugging CUDA applications running on actual hardware. CUDA-GDB is an extension to the x86-64 port of GDB, the GNU Project debugger.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/compute-sanitizer/index.html"><span class="doc">Compute Sanitizer</span></a></dt><dd><p>The user guide for Compute Sanitizer.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/nsightee-plugins-install-guide/index.html"><span class="doc">Nsight Eclipse Plugins Installation Guide</span></a></dt><dd><p>Nsight Eclipse Plugins Installation Guide</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/nsight-eclipse-plugins-guide/index.html"><span class="doc">Nsight Eclipse Plugins Edition</span></a></dt><dd><p>Nsight Eclipse Plugins Edition getting started guide</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/nsight-systems/index.html"><span class="doc">Nsight Systems</span></a></dt><dd><p>The documentation for Nsight Systems.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/nsight-compute/index.html"><span class="doc">Nsight Compute</span></a></dt><dd><p>The NVIDIA Nsight Compute is the next-generation interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/index.html"><span class="doc">Nsight Visual Studio Edition</span></a></dt><dd><p>The documentation for Nsight Visual Studio Edition.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html"><span class="doc">Profiler</span></a></dt><dd><p>This is the guide to the Profiler.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html"><span class="doc">CUDA Binary Utilities</span></a></dt><dd><p>The application notes for cuobjdump, nvdisasm, and nvprune.</p>
</dd>
</dl>
</section>
<hr class="docutils" />
<section id="white-papers">
<h2>White Papers<a class="headerlink" href="#white-papers" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/floating-point/index.html"><span class="doc">Floating Point and IEEE 754</span></a></dt><dd><p>A number of issues related to floating point accuracy and compliance are a frequent source of confusion on both CPUs and GPUs. The purpose of this white paper is to discuss the most common issues related to NVIDIA GPUs and to supplement the documentation in the CUDA C++ Programming Guide.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/incomplete-lu-cholesky/index.html"><span class="doc">Incomplete-LU and Cholesky Preconditioned Iterative Methods</span></a></dt><dd><p>In this white paper we show how to use the cuSPARSE and cuBLAS libraries to achieve a 2x speedup over CPU in the incomplete-LU and Cholesky preconditioned iterative methods. We focus on the Bi-Conjugate Gradient Stabilized and Conjugate Gradient iterative methods, that can be used to solve large sparse nonsymmetric and symmetric positive definite linear systems, respectively. Also, we comment on the parallel sparse triangular solve, which is an essential building block in these algorithms.</p>
</dd>
</dl>
</section>
<hr class="docutils" />
<section id="application-notes">
<h2>Application Notes<a class="headerlink" href="#application-notes" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-for-tegra-appnote/index.html"><span class="doc">CUDA for Tegra</span></a></dt><dd><p>This application note provides an overview of NVIDIA® Tegra® memory architecture and considerations for porting code from a discrete GPU (dGPU) attached to an x86 system to the Tegra® integrated GPU (iGPU). It also discusses EGL interoperability.</p>
</dd>
</dl>
</section>
<hr class="docutils" />
<section id="compiler-sdk">
<h2>Compiler SDK<a class="headerlink" href="#compiler-sdk" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/libnvvm-api/index.html"><span class="doc">libNVVM API</span></a></dt><dd><p>The libNVVM API.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/libdevice-users-guide/index.html"><span class="doc">libdevice User’s Guide</span></a></dt><dd><p>The libdevice library is an LLVM bitcode library that implements common functions for GPU kernels.</p>
</dd>
<dt><a class="reference internal" href="https://docs.nvidia.com/cuda/nvvm-ir-spec/index.html"><span class="doc">NVVM IR</span></a></dt><dd><p>NVVM IR is a compiler IR (intermediate representation) based on the LLVM IR. The NVVM IR is designed to represent GPU compute kernels (for example, CUDA kernels). High-level language front-ends, like the CUDA C compiler front-end, can generate NVVM IR.</p>
</dd>
</dl>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
  <img src="https://docs.nvidia.com/cuda/_static/NVIDIA-LogoBlack.svg" class="only-light"/>
<img src="https://docs.nvidia.com/cuda/_static/NVIDIA-LogoWhite.svg" class="only-dark"/>

<p class="notices">
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">Manage My Privacy</a>
|
<a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">Do Not Sell or Share My Data</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a>
|
<a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a>
|
<a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a>
</p>
    <p>&#169; Copyright 2007-2025, NVIDIA Corporation &amp; affiliates. All rights reserved.
      <span class="lastupdated">Last updated on Jun 5, 2025.
      </span></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
